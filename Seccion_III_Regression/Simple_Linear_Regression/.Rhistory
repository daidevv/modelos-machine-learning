devtools::install_github("r-lib/rlang", build_vignettes = TRUE)
devtools::install_github("r-lib/rlang", build_vignettes = TRUE)
remove.packages(rlang)
install.packages("rlang")
install.packages("rlang")
install.packages("https://cran.r-project.org/src/contrib/Archive/rlang/rlang_1.0.6.tar.gz", repos = NULL, type="source")
install.packages("https://github.com/r-lib/rlang/tree/v1.0.6", repos = NULL, type="source")
install.packages("rlang")
install.packages("rlang")
install.packages("rlang")
install.packages("rlang")
install.packages('rlang')
library(rlang)
detach("package:rlang", unload = TRUE)
library(rlang)
install.packages('rlang')
install.packages("rlang")
library(rlang)
install.packages("rlang")
install.packages("rlang")
library(rlang)
detach("package:rlang", unload = TRUE)
install.packages("rlang")
setwd("~/Documents/Cosas_Daiana/02_ Udemy/Machine Learning/00_Scripts/Seccion_III_Regresión/Regresion lineal simple")
dataset = read.csv("Salary_Data.csv")
#División de los datos para la fase de entrenamiento y para la fase de test
install.packages("caTools")
library(caTools)
set.seed(123)
split = sample.split(dataset$Salary, SplitRatio = 2/3)
training_set = subset(dataset, split == TRUE)
testing_set = subset(dataset, split == FALSE)
#Escalado de valores numéricos
#training_set[,2:3] = scale(testing_set[,2:3])
#testing_set[,2:3] = scale(testing_set[,2:3])
#Ajustamos el modelo de regresión lineal simple con el conj. de entrenamiento
#Uso de la funcion lm(linear model) porque nos sirve para crear automaticamente un modelo lineal
#A la funcion lm le pasamos la variable dependiente en funcion de la
#Aca decimos que la variable dependiente Salary sea en funcion ~ de la variable indep. YearsExperience
# ~ significa "en relacion a " o "en funcion de"
#El modelo lineal, ademas, espera un sefundo argumento que es el conj de datos (debemos especificar el dataset)
regressor = lm(formula = Salary ~ YearsExperience,
data = training_set)
#Predecimos resultados con el conj. de set
#(Esto se hace con el modelo ya entrenado con los valores de la recta de regresion lineal
#que vimos con el summary de la prediccion tec la ordenada al origen y la pendiente)
#Creamos un vector de resultados y usamos la funcion predict del paquete stats (funcion generica que hace predcciones indicandole el modelo de machine learning)
#y_pred indica que la funcion predict le indicamos primero el modelo de ML, es decir el modelo de prediccion
#y luego debe suinistrarsele el newdata, es decir los nuevos datos que se van a utilizar para hacer
#la prediccion, en este caso se va a utilizar el conjunto de testing
#al usar newdata siempre se debe tec usar correctamente el mismo nombre de las columnas que se llamaban para poder hacer la prediccion, sino no se podrá matchear la variable
y_pred = predict(regressor, newdata = testing_set)
#Instalamos la libreria ggplot2 para la representacion gráfica de todo tipo en R. (Forma parte del paquete Tidyverse)
#Visualizamos los resultados en el conjunto de entrenamiento
install.packages("ggplot2")
library(ggplot2)
#Agregamos las "capas de representacion" de ggplot: primero suministramos los datos,
#luego indicamos que columnas van en el eje X, luego en el eje y, le añadimos un titulo
# una etiqueta al eje x, y luego dibujaremos encima la recta de regresión.
#geom_point indica la geometria del punto
#Con aes precisamos cuaes van a ser el eje x y el eje y de nuestro gráfico. Osea, indicamos la apariencia de los puntos
ggplot() +
geom_point(aes(x = training_set$YearsExperience, y = training_set$Salary),    #una capa de visualizacion:pintamos una serie de puntos, para ello, precisamos cuales van a ser los ejes de X y de y
colour = "red") + #pongo + para seguir agregando componentes
geom_line(aes(x = training_set$YearsExperience, y = predict(regressor, newdata = training_set)),
colour = "blue") +
ggtitle("Sueldo vs. Años de experiencia (conj. de entrenamiento)") +
xlab("Años de experiencia") +
ylab("Sueldo (en $)")
ggplot() +
geom_point(aes(x = testing_set$YearsExperience, y = testing_set$Salary),    #una capa de visualizacion:pintamos una serie de puntos, para ello, precisamos cuales van a ser los ejes de X y de y
colour = "red") + #pongo + para seguir agregando componentes
geom_line(aes(x = training_set$YearsExperience, y = predict(regressor, newdata = training_set)),
colour = "blue") +
ggtitle("Sueldo vs. Años de experiencia (conj. de testing)") +
xlab("Años de experiencia") +
ylab("Sueldo (en $)")
